{
	"plots_dir": ["experiments/rc_atari/paper"],
	"plots":
	[
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "BeamRiderNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_beamrider_dqn"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["DeepQLearning"],

			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "BeamRiderNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_beamrider_ppo"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["ProximalPolicyOptimization"],

			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "BeamRiderNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_beamrider_sac"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["SoftActorCritic"],

			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "MsPacmanNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_mspacman_dqn"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["DeepQLearning"],

			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "MsPacmanNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_mspacman_ppo"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["ProximalPolicyOptimization"],

			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "MsPacmanNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_mspacman_sac"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["SoftActorCritic"],

			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "SeaquestNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_seaquest_dqn"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["DeepQLearning"],

			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "SeaquestNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_seaquest_ppo"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["ProximalPolicyOptimization"],

			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "SeaquestNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_seaquest_sac"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["SoftActorCritic"],

			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "SpaceInvadersNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_spaceinvader_dqn"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["DeepQLearning"],


			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "SpaceInvadersNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_spaceinvader_ppo"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["ProximalPolicyOptimization"],


			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "SpaceInvadersNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_spaceinvader_sac"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["SoftActorCritic"],


			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "PongNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_pong_dqn"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["DeepQLearning"],


			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "PongNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_pong_ppo"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["ProximalPolicyOptimization"],


			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "PongNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_pong_sac"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["SoftActorCritic"],


			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "BreakoutNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_breakout_dqn"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["DeepQLearning"],

			"curve_labels": [["TD", "RVI", "MA", "No RC"]],
			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "BreakoutNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_breakout_ppo"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["ProximalPolicyOptimization"],


			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		},
		{
			"in_out_files": [
				{
					"exp_input_file": ["experiments/rc_atari/inputs.json"],
					"exp_output_dir": ["experiments/rc_atari/"],
					"env": [[{"env_name": "BreakoutNoFrameskip-v4", "max_num_frames_per_episode": 1e9, "reset_cost_wrapper": true, "random_reset_prob": 0, "reset_cost": 1, "is_continuing": true}]],
					"suffix": ["average_clipped_reward"],
					"linestyle": ["solid"]
				}
			],
			"reward_centering": [
				{
					"reward_centering:type":["TD"],
					"reward_centering:initialize_reward_rate": [true],
					"reward_rate_optimizer:type": ["SGD"]
				},
				{
					"reward_centering:type":["RVI"]
				},
				{
					"reward_centering:type":["MA"]
				},
				{
					"reward_centering:type":[null]
				}
			],
			"type": ["learning_curve"],
			"name": ["learning_curves_breakout_sac"],
			"num_runs": [10],
			"x-label": ["x 100000 steps"],
			"label_loc": ["lower right"],
			"policy_learner:type": ["SoftActorCritic"],


			"title": ["PPO"],

			"criterion": ["all_max"],
			"top_k": [1],
			"plot_percentage": [1]
		}
	]
}
